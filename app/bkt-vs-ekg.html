<!doctype html>
<head>
  <link rel="stylesheet" href="app.css">
</head>

<body>
  <main>
    <section style="margin-left:5%;margin-right:5%">
      <h2>Bayesian Knowledge Tracing vs. Expert Designed Graphs</h2>

      <p>Bayesian knowledge tracing (BKT) and Expert-Designed knowledge graphs (EKG) are two popular approaches which share the goal of estimating the ‘knowledge’ state of a student as they interact with coursework.  In this short summary, I will first describe the details of each model, their individual strengths and weaknesses, followed by a contrast of their approaches.</p>

      <h3>Bayesian Knowledge Tracing</h3>

      <p>BKT is a model that estimates the probability that a concept has been learned given performance over a sequence of test questions <sup><a style="color:yellow" href="http://liris.cnrs.fr/~pchampin/2014/m2iade-ia2/_static/893CorbettAnderson1995.pdf">1</a></sup>.  To achieve this, BKT models a student’s latent knowledge state for a particular concept as a binary variable (representing unlearned [0] or learned [1]).  The BKT model is composed of a set of four parameters that can be empirically derived from the data, or manually set.  The first parameter, p(L0), is the probability that the content has already been learned prior to the set of test questions.  This could include prior history with the material, or a reading of the material immediately preceding the test questions.  The second parameter, p(T) is the probability that on any given trial, a knowledge state will transition from an unlearned state to a learned state.  The parameter only influences unlearned to learned transitions, as ‘unlearning’ is not possible in this model.  The third parameter, p(G), is the probability that a question will be guessed correctly, even if the concept is not learned.  Finally, the fourth parameter, p(S), represents the probability that a concept has been learned but the question was answered incorrectly (i.e. a slip).  These parameters are integrated in the context of a Bayesian inference scheme to update the probability (response-by-response) that a concept has been learned.</p>
      <p>One benefit of using this inference scheme is that it allows for a response-by-response probability estimate that a concept has been learned, which is extremely useful for adaptive learning systems.  Because a knowledge estimate can be derived after each test question, this allows the teacher/programmer to define a statistical threshold to consider the current concept learned and cue up the next concept.  Another desirable feature of this system is that the ‘content’ of the concept does not have to be explicitly represented by the system. Because the knowledge probability estimates are based solely on the response sequence profiles of the student, the system is content-agnostic, making it flexible for diverse sets of study material.  Finally, these individual BKTs can be integrated into a Bayesian network, allowing for multiple concepts to be represented, as well as the covariance structure between them.  Using modern machine learning approaches (for example, recurrent neural networks <sup><a style="color:yellow" href="https://papers.nips.cc/paper/5654-deep-knowledge-tracing.pdf">2</a></sup>), the covariance structure between the BKTs can be learned without expert mediation.
      <p>For a visualization of Bayesian Knowledge Tracing and the influence of the parameters and response sequence on the probability estimates, please see this web app that I built <a style="color:yellow" href="index.html">here.</a></p>

        <h3>Expert-Designed Knowledge Graphs</h3>

        <p>Expert-designed knowledge graphs (EKGs) are statistical graphs where the values of individual nodes represent knowledge of a particular concept (or collections of concepts) and the edges shared between the nodes represent the covariance or influence one concept has on the knowledge of another.  The ‘expertise’ stems from the fact that experts on the subject matter manually create these graph architectures.  One such example of an EKG is Knewton’s Knowledge Graph <sup><a style="color:yellow" href="https://www.knewton.com/resources/blog/adaptive-learning/the-knewton-knowledge-graph-a-cross-disciplinary-approach/">3</a></sup>.  This particular implementation of a knowledge graph is hierarchical, meaning that higher order concepts are ‘prerequisites’ of multiple lower order concepts.  Furthermore, the graphs (appear to be) directed, such that knowledge of a particular concept might influence the knowledge of another but not vice versa.  The primary advantage of this approach seems to be that the knowledge structures are built from scratch using decades of expert-tailored research.  Another advantage is that EKGs are easy to interpret since field experts code each concept and connections between concepts.  However, this ‘expert coding’ is a double-edged sword: while the graphs may be expert-tailored and easy to interpret, they may take week or months of expert work to construct an custom knowledge graph 2, causing them to be (potentially) ill-suited for modeling highly diverse educational material (such as datasets from MOOCs) and not easily scalable.</p>

        <h3>Summary</h3>

        <p>Both BKT and EKGs attempt to model knowledge states of students as they interact with test material. While EKGs require experts to manually create knowledge graphs, data-driven approaches (such as BKT) can generate inferences and integrate into graphs autonomically.  Using modern machine learning techniques in conjunction with probabilistic graphical modeling, knowledge graphs can be autonomically constructed based on the variance/covariance structure of the test responses over students.  This gives the Bayesian network approach an advantage because it allows for the modeling of diverse sets of content that would otherwise require many hours of manual labor to create.</p>
        <p>At first glance, it may seem that more autonomic approaches are outright superior to expert tailored graphs.  However, there are certain caveats to completely autonomous approaches that are worth mentioning.  Whereas concepts and relationships between concepts are clear and often intuitive in expert designed systems, models that are created completely autonomously lack transparency and often the model parameters and recovered ‘conceptual structure’ can be ambiguous and difficult to interpret.  Thus, debugging and optimizing these systems can be challenging.  Relatedly, the meaning of the latent states and their relationship to the test questions can often be ambiguous.  For instance, the model assumes one concept per set of test responses, whereas in practice each question likely contains multiple concepts.  Nonetheless, BKTs (and their network counterparts) perform very well in practice, and critically, they are extremely useful due to their automaticity, flexibility and scalability.</p>
        <p>For both of these frameworks, there is room for improvement.  Knowledge graphs (in their raw form) don’t consider differences in student ability and differences in test question difficulty/discriminability.  Variance in these parameters has been demonstrated to improve the reliability of Bayesian knowledge models <sup><a style="color:yellow" href="https://www.cs.cmu.edu/~listen/pdfs/hotDINA_poster.pdf">4</a></sup>.  One notable model that can be used in the context of both of these frameworks is item-response theory (IRT).  In IRT, test questions are modeled as a three parameter logistic model, which represents the probability that a student will answer the question correctly, given their ‘ability’ (see <a style="color:yellow" href="index.html">here</a> for a visualization of IRT).  In summary, Using IRT to account for across-student/test question variability may help to improve the predictive power of knowledge graphs.</p>
      </section>
  </main>
</body>
